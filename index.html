<!DOCTYPE html>

<HTML>
<HEAD>
  <META content="IE=5.0000" http-equiv="X-UA-Compatible">
  <META name="description" content="Guangqian Guo's home page"> 
  <META http-equiv="Content-Type" content="text/html; charset=gb2312">
  <LINK href="files/doc.css" 
    rel="stylesheet" type="text/css"> 
  <TITLE>Guangqian Guo</TITLE> 
  <META name="GENERATOR" content="MSHTML 11.00.10570.1001">
</HEAD>


<BODY> 
  <DIV id="layout-content" style="margin-top: 25px;">
  <TABLE>
    <TBODY>
    <TR>
      <TD width="670">
        <DIV id="toptitle">
        <H1>Guangqian Guo &nbsp;</H1></DIV>
        <H3>Ph.D. candidate</H3>
        <BR>Unmanned Systems Technology Research Institute
        <BR>Northwestern Polytechnical University
        <BR>Xi'an, China.
        <BR> Email:  
        <A href="mailto:guogq21@mail.nwpu.edu.cn"> guogq21@mail.nwpu.edu.cn</A>; 
        <BR></P>
      </TD>
      <TD>
        <IMG width="150" src="files/photo.jpg" border="0">
      </TD>
    </TR>
    <TR></TR></TBODY>
  </TABLE>
  <DIV id="layout-content" style="margin-top: 25px;">

  <H2>Biography</H2>
  <P> I am a Ph.D. candidate at the Unmanned Systems Technology Research Institute, Northwestern Polytechnical University (NWPU). My research interests include visual perception and weakly-supervised learning, specifically for Tiny Object Detection, Foundation-Model-based Scene Perception, and Weakly/Point-supervised Object Detection 
.</P>

 <H2>Recent News</H2>
    <P> 2024/04     I have one conference paper (first author) accepted by IJCAI-24. </P>
    <P> 2024/02     I have one journal paper (co-first author) accepted by TGRS. </P>
    <P> 2023/05     I have one journal paper (first author) accepted by TCSVT. </P>
    
  
  <H2>Publications</H2>
    <table class="pub_table">
    <!-- <tbody> -->
      <tr>
        <td class="pub_td1"><img src="files/PaperFig/p2p-ijcai" class="papericon"></td>
        <td 
          class="pub_td2"><u><b>Guangqian Guo</b></u>, Dian Shao, Chenguang Zhu, Sha Meng, Xuan Wang, Shan Gao
          <br><b>P2P: Transforming from Point Supervision to Explicit Visual Prompt for Object Detection and Segmentation</b>
          <br> INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (<b>IJCAI</b>), 2024
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/hanet.png" class="papericon"></td>
        <td 
          class="pub_td2"><u><b>Guangqian Guo</b></u>, Pengfei Chen, Xuehui Yu, Zhenjun Han, Qixiang Ye, Shan Gao
          <br><b>HANet: Save the Tiny, Save the All: Hierarchical Activation Network for Tiny Object Detection</b>
          <br> IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2023
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/rpg.png" class="papericon"></td>
        <td 
          class="pub_td2">&ast;Chaowei Wang, &ast;<u><b>Guangqian Guo</b></u>, Chang Liu, Dian Shao, Shan Gao
          <br><b>Effective Rotate: Learning Rotation-robust Prototype for Aerial Object Detection</b>
          <br> &ast; Equal Contribution
          <br> IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>), 2024
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/hybrid-net.png" class="papericon"></td>
        <td 
          class="pub_td2">Shan Gao (Ph.D. advisor), <u><b>Guangqian Guo</b></u>, Hanqiao Huang, C. L. Philip Chen
          <br><b>Go deep or broad? Exploit hybrid network architecture for weakly supervised object classiÔ¨Åcation and localization</b>
          <br> IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>), 2023
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/bls-event.png" class="papericon"></td>
        <td 
          class="pub_td2">Shan Gao, &ast;<u><b>Guangqian Guo</b></u>, C. L. Philip Chen
          <be> <b>Event-Based Incremental Broad Learning System for Object Classification</b>
          <br>  &ast; Work as Intern Student
          <br> IEEE International Conference on Computer Vision Workshop (<b>ICCVW</b>), 2019
          
        </td>
      </tr>
    </table>

    <H2>Submissions</H2>
    <LI> I have three papers submitted to ECCV 2024 (one as the first author),  2024/03. </LI>
    

    <H2>Awards</H2>
        <LI>	The First Prize Scholarship for Ph.D. of Northwestern Polytechnical University, 2023  </LI> 
        <LI>	Outstanding Graduate Student of Northwestern Polytechnical University, 2022  </LI> 
        <LI>	The First Prize Scholarship for M.S of Northwestern Polytechnical University, 2021  </LI> 
        <LI>	Outstanding Graduates of Colleges and Universities in Shaanxi Province, 2021  </LI> 
        <LI>  National Encouragement scholarship, 2019, 2020 </LI>
        <LI>	National Scholarship, 2018  </LI> 
        <LI>  The Third Prize of National English Competition, 2018, 2019 </LI> 
        <LI>  The Third Prize of the Chinese Mathematics Competition, 2018 </LI> 
      
  
    <!-- <H2>Github Statistics</Source></H2>
      <td class="pub_td1"><img src="https://github-readme-stats.vercel.app/api?username=pengzhiliang&show_icons=true&include_all_commits=true&title_color=2c86ea&icon_color=2c86ea&text_color=00c800&bg_color=00000000"></td>
    
  
  <br> <br> 
  <H2>Statistics</H2>
  <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5063gq35g0n&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>
-->
</BODY>
</HTML>
